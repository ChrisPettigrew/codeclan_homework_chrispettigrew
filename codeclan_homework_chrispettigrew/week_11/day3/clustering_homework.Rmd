---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(janitor)
library(rpart)
library(rpart.plot)
library(dplyr)
library(cluster)
library(factoextra)
library(dendextend)
```

```{r}
avos <- read_csv("data/avocado.csv")
```

```{r}
head(avos)
```

```{r}
avos_clean <- avos %>%
  clean_names() 
  
avos_tree <- avos_clean %>%
  select(total_volume, type)

```

```{r}
# get how many rows we have in total to work out the percentage
n_data <- nrow(avos_tree)

# create a test sample index
test_index <- sample(1:n_data, size = n_data*0.2)

# create test set
avos_test  <- slice(avos_tree, test_index)

# create training set
avos_train <- slice(avos_tree, -test_index)
```

```{r}
avos_test %>%
 janitor::tabyl(type)
```

```{r}
avos_train %>%
 janitor::tabyl(type)
```

```{r}
avos_fit <- rpart(type ~ ., 
                     data = avos_train, 
                     method = 'class')

rpart.plot(avos_fit, yesno = 2)
```

```{r}
rpart.rules(avos_fit, cover = TRUE)

```

# clustering

```{r}
computers <- read_csv("data/computers.csv")
```

```{r}
head(computers)
```


```{r}
comp_clean <- computers %>%
  clean_names()
```

```{r}
comp_comp <- comp_clean %>%
  select(c(hd, ram))
```

```{r}
comp_scale <- comp_comp %>%
  mutate_all(scale)
```


```{r}
ggplot(comp_scale, aes(hd, ram)) +
  geom_point()
```

```{r}
clustered_comp <- kmeans(comp_scale, centers = 6, nstart = 25)
clustered_comp
```

```{r}
library(broom)

tidy(clustered_comp, 
     col.names = colnames(comp_scale))
```

```{r}
library(animation)

comp_scale %>% 
  kmeans.ani(centers = 6) 
```

